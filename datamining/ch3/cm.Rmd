---
title: 分类模型
author:
 - 授课教师：吴翔 \newline
 - 邮箱：wuhsiang@hust.edu.cn
date: "March 18-25, 2019"
linestretch: 1.25
fontsize: 18
header-includes:
  - \usepackage{ctex}
output:
  beamer_presentation:
    theme: "CambridgeUS"
    colortheme: "beaver"
    latex_engine: xelatex
    toc: true
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
options(digits = 2)

```

# 统计学习概述

## 统计学习方法

统计机器学习（statistical machine learning）可分为：

- 有监督学习（supervised learning） vs 无监督学习（unsupervised learning）：聚类分析即为典型的无监督学习
- 参数方法（parametric methods） vs 非参数方法（non-parametric methods）
- 回归（regression）问题 vs \textcolor{red}{分类（classification）问题}：分别针对连续变量和分类变量

## 测试均方误差的分解

测试均方误差的期望值（expected test MSE）可以分解为如下三个部分：
$$
E(y - \hat{f}(x))^{2} = \underbrace{\text{Var}(\hat{f}(x))}_{\text{variance}} + \underbrace{[\text{Bias}(\hat{f}(x))]^{2}}_{\text{bias}} + \underbrace{\text{Var}(\epsilon)}_{\text{irreducible}}.
$$

- 模型方差（variance）：针对不同的训练数据，$\hat{f}$的变化程度。
- 模型偏误（bias）：通过相对简化的模型来**近似**真实世界的问题时所引入的误差。


## 权衡模型偏误与方差

![bias-variance trade-off](figures/biasvariance.png){width=70%}


## 如何选择统计模型？

- 传统统计模型的局限：线性回归模型等统计模型通常最小化训练数据的均方误差，但是其测试均方误差（test MSE）却较大。换言之，传统统计模型执着于寻求“真实规律”，以致于将一些随机因素**误判**为$f$的真实性质。
- 权衡模型偏误与方差（bias-variance trade-off）：随着模型灵活性（或自由度）的增加，模型方差随之增大，但模型偏误则相应减小（过度拟合问题）。通过交叉验证（cross-validation）来实现两者的权衡。
- 权衡预测精度与可解释性（accuracy-interpretability trade-off）：诸如bagging、boosting、support vector machines等非线性模型具有很高的预测精度，但不易解释；linear models等易于解释，但预测精度不高。两者的权衡取决于研究目的。

## 交叉验证

交叉验证将原始数据集分为训练集（training set）和验证集（validation set），并以验证集的错误率选择最佳模型。

- 留一交叉验证法（leave-one-out cross validation, LOOCV）
- $k$折交叉验证法（$k-$fold CV）：将观测集随机分为$k$个大小基本一致的组，或说折（fold）。每次选取其中一折作为验证集，而剩余$k-1$折作为训练集。通常，取$k=5$或$k=10$。

分类模型验证集错误率：
$$
\text{CV}_{(k)} = \frac{1}{k} \sum_{i=1}^{k} \text{Err}_{k} = \frac{1}{k} \sum_{i=1}^{k} \frac{1}{m_{k}} \sum_{i=1}^{m_{k}} I(y_{i} \neq \hat{y}_{i}).
$$


## 分类模型概述

预测分类响应变量（categorical response variable）：

1. 基本分类模型（basic classifier）
2. 树模型（tree-based models）
3. 支持向量机（support vector machine, SVM）
4. 聚类模型（clustering models）

## 分类模型的评价

![confusion matrix](figures/confusionmatrix.png){width=90%}

## ROC曲线

## AUC

# 基本分类模型

## 基本分类模型（basic classifier）

1. 逻辑斯蒂回归（logistic regression）
2. 线性判别分析（linear discriminant analysis, LDA）
3. 二次判别分析（quadratic discriminant analysis, QDA）
4. $K$最近邻（$K-$nearest neighbor, KNN）

## logistic回归

给定$X$条件下事件$Y$发生的概率$p(X) = \text{Pr}(Y=1|X)$，据此可以将发生比（odd）的对数建模为$X$的线性函数
$$
\text{log}[\frac{p(X)}{1-p(X)}] = \beta X.
$$
上式左侧称为对数发生比（log-odd）或分对数（logit），其取值范围在$(-\infty, \infty)$。

当类别$K \geq 2$时，则采用多类别logistic回归模型。

## LDA

## QDA

## KNN

# 聚类模型

## 聚类模型（clustering models）

1. $K$均值聚类（$K-$means clustering）
2. 系统聚类（hierarchical clustering）

## $K$均值聚类


# 树模型

## 树模型（tree-based models）

1. 决策树
2. 装袋法（bagging）
3. 随机森林（random forest）
4. 提升法（boosting）

## 决策树

# 支持向量机

## 支持向量机
